# -*- coding: utf-8 -*-
"""JackyChung_HW02_Lab2.2-Transfer Learning_for_stu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14gGfQkp7KLaTF9OduqTvnKe9xdVqaNwT

# Lab 2.2: Transfer Learning
Lab2.2會比較基本的CNN的分類表現和轉移學習後的VGG16表現

# Import dataset
[Dataset](https://drive.google.com/file/d/1E3wSi00Po3-SiqKa-yiu6wRKzyunhrF7/view?usp=sharing)

Info:
* train:101/class
* test:50/class
* validation:50/class



1.   Mount your google drive
2.   Unzip data.zip
3.   Change runtime type to GPU

# Baseline
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip "/content/drive/MyDrive/Colab Notebooks/data.zip"



# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# %config InlineBackend.figure_format = 'retina'
import matplotlib.pyplot as plt
plt.style.use('ggplot')
import pandas as pd
import numpy as np
import seaborn as sns
import warnings
import os
import pickle
import tensorflow as tf

warnings.filterwarnings('ignore')
pd.options.display.float_format = '{:,.2f}'.format
pd.set_option('display.max_rows', 100)
pd.set_option('display.max_columns', 200)

from __future__ import print_function
from tensorflow.keras.models import Model, Sequential, load_model
from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten, Dropout
from tensorflow.keras.datasets import mnist
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import backend as K
from vis.utils import utils
from tensorflow.keras import activations
#from vis.visualization import visualize_activation, get_num_filters
from vis.input_modifiers import Jitter



from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense
from tensorflow.keras import backend as K

"""# Utility Functions
我們以下會用視覺化的工具來幫助各位了解分類的結果。因此在這邊我們這邊先撰寫幾個utility function。函數的名字應該很好了解其功用，因此建議你可以直接看一下其功能後，就往下一個部分前進。
"""

def smooth_curve(points, factor=0.8):
    smoothed = []
    for point in points:
        if smoothed:
            previous = smoothed[-1]
            smoothed.append(previous * factor + point * (1 - factor))
        else:
            smoothed.append(point)
    return smoothed

def plot_compare(history, steps=-1):
    if steps < 0:
        steps = len(history.history['accuracy'])
    acc = smooth_curve(history.history['accuracy'][:steps])
    val_acc = smooth_curve(history.history['val_accuracy'][:steps])
    loss = smooth_curve(history.history['loss'][:steps])
    val_loss = smooth_curve(history.history['val_loss'][:steps])
    
    plt.figure(figsize=(6, 4))
    plt.plot(loss, c='#0c7cba', label='Train Loss')
    plt.plot(val_loss, c='#0f9d58', label='Val Loss')
    plt.xticks(range(0, len(loss), 5))
    plt.xlim(0, len(loss))
    plt.title('Train Loss: %.3f, Val Loss: %.3f' % (loss[-1], val_loss[-1]), fontsize=12)
    plt.legend()
    
    plt.figure(figsize=(6, 4))
    plt.plot(acc, c='#0c7cba', label='Train Acc')
    plt.plot(val_acc, c='#0f9d58', label='Val Acc')
    plt.xticks(range(0, len(acc), 5))
    plt.xlim(0, len(acc))
    plt.title('Train Accuracy: %.3f, Val Accuracy: %.3f' % (acc[-1], val_acc[-1]), fontsize=12)
    plt.legend()
    
def deprocess_image(x):
    # normalize tensor: center on 0., ensure std is 0.1
    x -= x.mean()
    x /= (x.std() + 1e-5)
    x *= 0.1

    # clip to [0, 1]
    x += 0.5
    x = np.clip(x, 0, 1)

    # convert to RGB array
    x *= 255
    x = np.clip(x, 0, 255).astype('uint8')
    return x
 
def save_history(history, fn):
    with open(fn, 'wb') as fw:
        pickle.dump(history.history, fw, protocol=2)

def load_history(fn):
    class Temp():
        pass
    history = Temp()
    with open(fn, 'rb') as fr:
        history.history = pickle.load(fr)
    return history

def jitter(img, amount=32):
    ox, oy = np.random.randint(-amount, amount+1, 2)
    return np.roll(np.roll(img, ox, -1), oy, -2), ox, oy

def reverse_jitter(img, ox, oy):
    return np.roll(np.roll(img, -ox, -1), -oy, -2)

def plot_image(img):
    plt.figure(figsize=(6, 6))
    plt.imshow(img)
    plt.axis('off')

"""# Image size
因為圖片的大小是150 x 150，所以我們設定圖片的長和寬。 並且設定train和validation的目錄。
"""

# dimensions of our images.
img_width, img_height = 150, 150

train_data_dir = './data/train'
validation_data_dir = './data/validation'

"""# Data Generator
Keras針對圖片數量不夠多的問題，也提供了解法：利用ImageDataGenerator，我們可以利用一張圖片，進行若干運算之後，得到不同的圖片。 

參考：https://zhuanlan.zhihu.com/p/30197320
"""

batch_size=16

# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

# this is the augmentation configuration we will use for testing:
# only rescaling
test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')

"""我們可以利用以下的code來看看結果：
1. 首先初始化一個物件datagen，設定好資料增強參數
2. 讀取一個範例圖片並生成增強後的圖片觀察結果
"""

from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')

img = load_img('data/train/cats/cat.0.jpg')  # this is a PIL image
x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)
x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)


i = 0
for batch in datagen.flow(x, batch_size=1,save_to_dir='data', save_prefix='cat', save_format='jpeg'):
    i += 1
    if i > 20:
        break  # otherwise the generator would loop indefinitely

"""檢查在data/資料夾下的檔案，會發現這個generator利用了cats.0.jpg產生了很多圖片

# Building a Convolutional Neural Network
"""

# 判斷RGB是在矩陣中的第幾個元素?
if K.image_data_format() == 'channels_first':
    input_shape = (3, img_width, img_height)
else:
    input_shape = (img_width, img_height, 3)

CNN_model = Sequential()
CNN_model.add(Conv2D(32, (3, 3), input_shape=input_shape))
CNN_model.add(Activation('relu'))
CNN_model.add(MaxPooling2D(pool_size=(2, 2)))

CNN_model.add(Conv2D(32, (3, 3)))
CNN_model.add(Activation('relu'))
CNN_model.add(MaxPooling2D(pool_size=(2, 2)))

CNN_model.add(Conv2D(64, (3, 3)))
CNN_model.add(Activation('relu'))
CNN_model.add(MaxPooling2D(pool_size=(2, 2)))

CNN_model.add(Flatten())
CNN_model.add(Dense(64))
CNN_model.add(Activation('relu'))
CNN_model.add(Dropout(0.2))
CNN_model.add(Dense(32))
CNN_model.add(Activation('relu'))
CNN_model.add(Dense(1))
CNN_model.add(Activation('sigmoid'))

CNN_model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
metrics=['accuracy'])

"""# Training
因為我們準備的training data和validation data都是利用generator的形式，因此我們在指定輸入資料就直接將輸入資料就直接將train_generator輸入即可
"""

CNN_history = CNN_model.fit(train_generator, epochs=15, validation_data=validation_generator, verbose=1)

"""我們可以利用model.save()這個函數，將model存起來供以後使用。"""

CNN_model.save('CNN_model.h5')
save_history(CNN_history, 'CNN_history.bin')

CNN_history = load_history('CNN_history.bin')
plot_compare(CNN_history)

"""# VGGNet
Keras.applications套件有提供一系列的影像辨識模型，其中經典例子-VGG16較為常用，載入模型的時候可以調整一些參數:
* weights='imagenet' : 選擇是否要載入訓練好的權重(None or imagenet or "path to your weight")
* include_top=False  : 決定是否要載入全連接層
"""

from tensorflow.keras.applications import VGG16
import os
#Load the VGG model


vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))

"""可以使用keras.utils.plot_model印出模型結構"""

tf.keras.utils.plot_model(
    vgg_conv,
    to_file="model.png",
    show_shapes=False,
    show_dtype=False,
    show_layer_names=True,
    rankdir="TB",
    expand_nested=False,
    dpi=96,
)

from tensorflow.keras import models
from tensorflow.keras import layers
from tensorflow.keras import optimizers
 
# Create the model
VGG_model = models.Sequential()

# Add the vgg convolutional base model
VGG_model.add(vgg_conv)
 
# Add new layers
VGG_model.add(layers.Flatten())
VGG_model.add(layers.Dense(64, activation='relu'))
VGG_model.add(layers.Dropout(0.5))
VGG_model.add(layers.Dense(1, activation='sigmoid'))
 
# Show a summary of the model. Check the number of trainable parameters
VGG_model.summary()


VGG_model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
metrics=['accuracy'])

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_data_dir = './data/train'
test_data_dir = './data/test'
validation_data_dir = './data/validation'

batch_size = 16

# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

# this is the augmentation configuration we will use for testing:
# only rescaling
test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')

VGG_history = VGG_model.fit(train_generator,epochs=30,validation_data=validation_generator,verbose=1)

VGG_model.save('VGG_model.h5')
save_history(VGG_history, 'VGG_history.bin')

VGG_history = load_history('VGG_history.bin')
plot_compare(VGG_history)

"""# Layer Transfer

* 當具備少量的Target data時，如果直接訓練整個網路會造成Overfitting，於是我們需要凍結網路前段的特徵擷取參數，防止train下去網路壞掉。
"""

from tensorflow.keras.applications import VGG16
import os
#Load the VGG model


vgg_conv_transfer = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))

"""* 練習:VGG16的conv+maxpool為一個block，這裡修改最後一個block讓他和分類層一起訓練"""

for layer in vgg_conv_transfer.layers:
  print("{} : {}".format(layer.name,layer.trainable))

for layer in vgg_conv_transfer.layers[:-4]:
  layer.trainable = False

for layer in vgg_conv_transfer.layers[:]:
  print(layer.trainable)

"""把修改的特徵擷取Layer加上後半部的分類網路訓練"""

from tensorflow.keras import models
from tensorflow.keras import layers
from tensorflow.keras import optimizers
 
# Create the model
VGG_model_transfer = models.Sequential()

# Add the vgg convolutional base model
VGG_model_transfer.add(vgg_conv_transfer)
 
# Add new layers
VGG_model_transfer.add(layers.Flatten())
VGG_model_transfer.add(layers.Dense(64, activation='relu'))
VGG_model_transfer.add(layers.Dropout(0.5))
VGG_model_transfer.add(layers.Dense(1, activation='sigmoid'))
 
# Show a summary of the model. Check the number of trainable parameters
VGG_model_transfer.summary()


VGG_model_transfer.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
metrics=['accuracy'])

VGG_history_transfer = VGG_model_transfer.fit(train_generator,epochs=30,validation_data=validation_generator,verbose=1)

VGG_model_transfer.save('VGG_model_transfer.h5')
save_history(VGG_history_transfer, 'VGG_history_transfer.bin')

VGG_history_transfer = load_history('VGG_history_transfer.bin')
plot_compare(VGG_history_transfer)

"""#Feature Map
我們可以用VGG16的中間層，來看看學出來的feature map長怎樣。

首先我們考慮這一只貓。
"""

from keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np

img_path = 'data/train/cats/cat.54.jpg'

img = image.load_img(img_path, target_size=(150, 150))
img_tensor = image.img_to_array(img)
img_tensor = np.expand_dims(img_tensor, axis=0)
img_tensor /= 255.

plt.imshow(img_tensor[0])
plt.axis('off')
plt.show()

# Freeze the layers except the last 4 layers
for layer in vgg_conv.layers[:-4]:
    layer.trainable = False
 
# Check the trainable status of the individual layers
for layer in vgg_conv.layers:
    print(layer, layer.trainable)

from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model

vgg = VGG16(weights='imagenet', include_top=False)

layer_outputs = [layer.output for layer in vgg.layers if 'conv1' in layer.name]
activation_model = Model(inputs=vgg.input, outputs=layer_outputs)
intermediate_activations = activation_model.predict(img_tensor)

first_layer_activation = intermediate_activations[0]

plt.imshow(first_layer_activation[0, :, :, 19], cmap='viridis')
plt.axis('off')
plt.show()

"""最後請比較三項訓練的結果差異"""

model = load_model('drive/MyDrive/Colab Notebooks/model.h5') # 導入CNN模組

total_img_cat=0   #Cat樣本總數
correct_img_cat=0  #Cat預測正確數量

for pname in os.listdir('data/test/cats/'):
    img_path = os.path.join('data/test/cats/', pname)
    img = image.load_img(img_path, target_size=(150, 150))
    img_tensor = image.img_to_array(img)
    img_tensor = np.expand_dims(img_tensor, axis=0)
    img_tensor /= 255.
    pred = model.predict(img_tensor)
    if pred[0] < 0.5:
        correct_img_cat += 1
    total_img_cat += 1

total_img_dog=0   #Dog樣本總數
correct_img_dog=0  #Dog預測正確數量

for pname in os.listdir('data/test/dogs/'):
    img_path = os.path.join('data/test/dogs/', pname)
    img = image.load_img(img_path, target_size=(150, 150))
    img_tensor = image.img_to_array(img)
    img_tensor = np.expand_dims(img_tensor, axis=0)
    img_tensor /= 255.
    pred = model.predict(img_tensor)
    if pred[0] > 0.5:
        correct_img_dog += 1
    total_img_dog += 1

total_img=0  #總樣本總數
correct_img=0 #總預測正確的數量
total_img  = total_img_cat  + total_img_dog
correct_img = correct_img_cat + correct_img_dog

print("CNN總預測正確的數量：" + str(correct_img) + "，CNN總樣本總數：" + str(total_img) + "，CNN總正確率：" + str(correct_img / total_img))

del model

model = load_model('VGG_model.h5') # 導入VGG模組

total_img_cat=0   #Cat樣本總數
correct_img_cat=0  #Cat預測正確數量

for pname in os.listdir('data/test/cats/'):
    img_path = os.path.join('data/test/cats/', pname)
    img = image.load_img(img_path, target_size=(150, 150))
    img_tensor = image.img_to_array(img)
    img_tensor = np.expand_dims(img_tensor, axis=0)
    img_tensor /= 255.
    pred = model.predict(img_tensor)
    if pred[0] < 0.5:
        correct_img_cat += 1
    total_img_cat += 1

total_img_dog=0   #Dog樣本總數
correct_img_dog=0  #Dog預測正確數量

for pname in os.listdir('data/test/dogs/'):
    img_path = os.path.join('data/test/dogs/', pname)
    img = image.load_img(img_path, target_size=(150, 150))
    img_tensor = image.img_to_array(img)
    img_tensor = np.expand_dims(img_tensor, axis=0)
    img_tensor /= 255.
    pred = model.predict(img_tensor)
    if pred[0] > 0.5:
        correct_img_dog += 1
    total_img_dog += 1

total_img=0  #總樣本總數
correct_img=0 #總預測正確的數量
total_img  = total_img_cat  + total_img_dog
correct_img = correct_img_cat + correct_img_dog

print("VGG總預測正確的數量：" + str(correct_img) + "，VGG總樣本總數：" + str(total_img) + "，VGG總正確率：" + str(correct_img / total_img))

del model

model = load_model('VGG_model_transfer.h5') # 導入VGG(transfer)模組

total_img_cat=0   #Cat樣本總數
correct_img_cat=0  #Cat預測正確數量

for pname in os.listdir('data/test/cats/'):
    img_path = os.path.join('data/test/cats/', pname)
    img = image.load_img(img_path, target_size=(150, 150))
    img_tensor = image.img_to_array(img)
    img_tensor = np.expand_dims(img_tensor, axis=0)
    img_tensor /= 255.
    pred = model.predict(img_tensor)
    if pred[0] < 0.5:
        correct_img_cat += 1
    total_img_cat += 1

total_img_dog=0   #Dog樣本總數
correct_img_dog=0  #Dog預測正確數量

for pname in os.listdir('data/test/dogs/'):
    img_path = os.path.join('data/test/dogs/', pname)
    img = image.load_img(img_path, target_size=(150, 150))
    img_tensor = image.img_to_array(img)
    img_tensor = np.expand_dims(img_tensor, axis=0)
    img_tensor /= 255.
    pred = model.predict(img_tensor)
    if pred[0] > 0.5:
        correct_img_dog += 1
    total_img_dog += 1

total_img=0  #總樣本總數
correct_img=0 #總預測正確的數量
total_img  = total_img_cat  + total_img_dog
correct_img = correct_img_cat + correct_img_dog

print("VGG(transfer)總預測正確的數量：" + str(correct_img) + "，VGG(transfer)總樣本總數：" + str(total_img) + "，VGG(transfer)總正確率：" + str(correct_img / total_img))

"""ans:VGG(transfer)>CNN>VGG

"""